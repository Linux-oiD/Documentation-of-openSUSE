<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
 <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
 <!ENTITY % entities SYSTEM "entity-decl.ent">
 %entities;
]>
<!--taroth 080403: maintainer: please take care of bug #374327 -->
<!--bg: which basically says, that nfs-server is not part of sled -->
<chapter id="cha.nfs">
 <title>Sharing File Systems with NFS</title><indexterm>
 <primary>NFS</primary></indexterm><indexterm>
 <primary>Network File System</primary>
 <see>NFS</see></indexterm>
 <para>
  Distributing and sharing file systems over a network is a common task in
  corporate environments. The proven <systemitem>NFS</systemitem> system
  works together with <systemitem>NIS</systemitem>, the yellow pages
  protocol. For a more secure protocol that works together with
  <systemitem>LDAP</systemitem> and may also be kerberized, check
  <systemitem>NFSv4</systemitem>.
 </para>
 <para>
  NFS with NIS makes a network transparent to the user. With NFS, it is
  possible to distribute arbitrary file systems over the network. With an
  appropriate setup, users always find themselves in the same environment
  regardless of the terminal they currently use.
 </para>
 <para os="osuse;sles">
  Like NIS, NFS is a client/server system. However, a machine can be
  both&mdash;it can supply file systems over the network (export) and mount
  file systems from other hosts (import).
 </para>
 <important os="osuse;sles">
  <title>Need for DNS</title>
  <para>
   In principle, all exports can be made using IP addresses only. To avoid
   time-outs, you need a working DNS system. DNS is necessary at least for
   logging purposes, because the mountd daemon does reverse lookups.
  </para>
 </important>
 <sect1 id="sec.nfs.installation">
  <title>Installing the Required Software</title>

  <para>
   To configure your host as an NFS client, you do not need to install
   additional software. All needed packages are installed by default.
  </para>

  <para os="osuse;sles">
   NFS server software is not part of the default installation. To install
   the NFS server software, start &yast; and select
   <menuchoice><guimenu>Software</guimenu> <guimenu>Software
   Management</guimenu></menuchoice>. Now choose
   <menuchoice><guimenu>Filter</guimenu>
   <guimenu>Patterns</guimenu></menuchoice> and select <guimenu>File
   Server</guimenu> or use the <guimenu>Search</guimenu> option and search
   for <literal>NFS Server</literal>. Confirm the installation of the
   packages to finish the installation process.
  </para>
 </sect1>
 <sect1 id="sec.nfs.import-yast2">
  <title>Importing File Systems with &yast;</title><indexterm>

  <primary>NFS</primary>

  <secondary>clients</secondary></indexterm>

  <para>
   Authorized users can mount NFS directories from an NFS server into the
   local file tree using the &yast; NFS client module. Click on
   <guimenu>Add</guimenu> and enter the hostname of the NFS server, the
   directory to import, and the mount point at which to mount this directory
   locally. The changes will take effect after <guimenu>Finish</guimenu> is
   clicked in the first dialog.
  </para>

  <para>
   In the <guimenu>NFS Settings</guimenu> tab, enable <guimenu>Open Port in
   Firewall</guimenu> to allow access to the service from remote computers.
   The firewall status is displayed next to the check box. When using NFSv4,
   make sure that the checkbox <guimenu>Enable NFSv4</guimenu> is enabled,
   and that the <guimenu>NFSv4 Domain Name</guimenu> contains the same value
   as used by the NFSv4 server. The default domain is
   <literal>localdomain</literal>.
  </para>

  <para>
   Click <guimenu>OK</guimenu> to save your changes. See
   <xref linkend="fig.yast2.nfs.client" xrefstyle="HeadingOnPage"/>.
  </para>

  <para>
   The configuration is written to <filename>/etc/fstab</filename> and the
   specified file systems are mounted. When you start the &yast;
   configuration client at a later time, it also reads the existing
   configuration from this file.
  </para>

  <figure id="fig.yast2.nfs.client">
   <title>NFS Client Configuration with YaST</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="yast2_nfsclient.png" width="75%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="yast2_nfsclient.png" width="75%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>
 </sect1>
 <sect1 id="sec.nfs.import">
  <title>Importing File Systems Manually</title><indexterm>

  <primary>NFS</primary>

  <secondary>importing</secondary></indexterm><indexterm>

  <primary>NFS</primary>

  <secondary>mounting</secondary></indexterm>

  <para>
   The prerequisite for importing file systems manually from an NFS server
   is a running RPC port mapper. Start it by entering <command>rcrpcbind
   <option>start</option></command> as
   <systemitem
   class="username">root</systemitem>. Then remote file
   systems can be mounted in the file system like local partitions using
   <command>mount</command>:
  </para>

<screen>mount <replaceable>host</replaceable>:<replaceable>remote-path</replaceable> <replaceable>local-path</replaceable>
</screen>

  <para>
   To import user directories from the <systemitem>&nfsname;</systemitem>
   machine, for example, use:
  </para>

<screen>mount &nfsname;:/home /home
</screen>

  <sect2 id="sec.nfs.automount">
   <title>Using the Automount Service</title>
   <para>
    The autofs daemon can be used to mount remote file systems
    automatically. Add the following entry in the your
    <filename>/etc/auto.master</filename> file:
   </para>
<screen>/nfsmounts /etc/auto.nfs</screen>
   <para>
    Now the <filename>/nfsmounts</filename> directory acts as the root for
    all the NFS mounts on the client if the <filename>auto.nfs</filename>
    file is filled appropriately. The name <filename>auto.nfs</filename> is
    chosen for the sake of convenience&mdash;you can choose any name. In
    <filename>auto.nfs</filename> add entries for all the NFS mounts as
    follows:
   </para>
<screen>localdata -fstype=nfs server1:/data
nfs4mount -fstype=nfs4 server2:/</screen>
   <para>
    Activate the settings with <command>rcautofs start</command> as
    &rootuser;. In this example, <filename>/nfsmounts/localdata</filename>,
    the <filename>/data</filename> directory of
    <systemitem>server1</systemitem>, is mounted with NFS and
    <filename>/nfsmounts/nfs4mount</filename> from
    <systemitem>server2</systemitem> is mounted with NFSv4.
   </para>
   <para>
    If the <filename>/etc/auto.master</filename> file is edited while the
    service autofs is running, the automounter must be restarted for the
    changes to take effect with <command>rcautofs restart</command>.
   </para>
  </sect2>

  <sect2 id="sec.nfs.fstab">
   <title>Manually Editing <filename>/etc/fstab</filename></title>
   <para>
    A typical NFSv3 mount entry in <filename>/etc/fstab</filename> looks
    like this:
   </para>
<screen>&nfsname;:/data /local/path nfs rw,noauto 0 0</screen>
   <para>
    NFSv4 mounts may also be added to the <filename>/etc/fstab</filename>
    file. For these mounts, use <literal>nfs4</literal> instead of
    <literal>nfs</literal> in the third column and make sure that the remote
    file system is given as <filename>/</filename> after the
    <replaceable>&nfsname;:</replaceable> in the first column. A sample line
    for an NFSv4 mount in <filename>/etc/fstab</filename> looks like this:
   </para>
<screen>&nfsname;:/ /local/pathv4 nfs4 rw,noauto 0 0</screen>
   <para>
    The <literal>noauto</literal> option prevents the file system from being
    mounted automatically at start up. If you want to mount the respective
    file system manually, it is possible to shorten the mount command
    specifying the mount point only:
   </para>
<screen>mount /local/path</screen>
   <para>
    Note, that if you do not enter the <literal>noauto</literal> option, the
    initialization scripts of the system will handle the mount of those file
    systems at start up.
   </para>
  </sect2>
 </sect1>
 <sect1 id="sec.nfs.export-yast2" os="osuse;sles">
  <title>Exporting File Systems with &yast;</title><indexterm>

  <primary>NFS</primary>

  <secondary>servers</secondary></indexterm>

  <para>
   With &yast;, turn a host in your network into an NFS server&mdash;a
   server that exports directories and files to all hosts granted access to
   it. This could be done to provide applications to all members of a group
   without installing the applications locally on each and every host. To
   install such a server, start &yast; and select <menuchoice>
   <guimenu>Network Services</guimenu><guimenu>NFS
   Server</guimenu></menuchoice>; see
   <xref
   linkend="fig.inst.nfsserver1" xrefstyle="HeadingOnPage"/>.
  </para>

  <figure id="fig.inst.nfsserver1">
   <title>NFS Server Configuration Tool</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="yast2_inst_nfsserver1.png" width="75%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="yast2_inst_nfsserver1.png" width="75%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para>
   Then activate <guimenu>Start</guimenu> and enter the <guimenu>NFSv4
   Domain Name</guimenu>.
  </para>

  <para>
   Click <guimenu>Enable GSS Security</guimenu> if you need secure access to
   the server. A prerequisite for this is to have Kerberos installed on your
   domain and to have both the server and the clients kerberized. Click
   <guimenu>Next</guimenu>.
  </para>

<!--
      the following only appears, if you select "Start": bnc#582228,
      ke: 2010-02-23
  -->

  <para>
   In the upper text field, enter the directories to export. Below, enter
   the hosts that should have access to them. This dialog is shown in
   <xref linkend="fig.inst.nfsserver2" xrefstyle="HeadingOnPage"/>. The
   figure shows the scenario where NFSv4 is enabled in the previous dialog.
   <literal>Bindmount Targets</literal> is shown in the right pane. For more
   details, click <guimenu>Help</guimenu>. In the lower half of the dialog,
   there are four options that can be set for each host: <option>single
   host</option>, <option>netgroups</option>, <option>wildcards</option>,
   and <option>IP networks</option>. For a more thorough explanation of
   these options, refer to the <option>exports</option> man page. Click
   <guimenu>Finish</guimenu> to complete the configuration.
  </para>

  <figure id="fig.inst.nfsserver2">
   <title>Configuring an NFS Server with &yast;</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="yast2_inst_nfsserver2.png" width="75%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="yast2_inst_nfsserver2.png" width="75%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <important>
   <title>Automatic Firewall Configuration</title>
   <para>
    If a firewall is active on your system (SuSEfirewall2), &yast; adapts
    its configuration for the NFS server by enabling the
    <literal>nfs</literal> service when <guimenu>Open Ports in
    Firewall</guimenu> is selected.
   </para>
  </important>

  <sect2 id="sec.nfs.exportv4">
   <title>Exporting for NFSv4 Clients</title>
   <para>
    Activate <guimenu>Enable NFSv4</guimenu> to support NFSv4 clients.
    Clients with NFSv3 can still access the server's exported directories if
    they are exported appropriately. This is explained in detail in
    <xref linkend="sec.nfs.export.coexisting" xrefstyle="HeadingOnPage"/>.
   </para>
   <para>
    After activating NFSv4, enter an appropriate domain name. Make sure the
    name is the same as the one in the <filename>
    /etc/idmapd.conf</filename> file of any NFSv4 client that accesses this
    particular server. This parameter is for the idmapd service that is
    required for NFSv4 support (on both server and client). Leave it as
    <literal>localdomain</literal> (the default) if you do not have special
    requirements. For more information, see the links in
    <xref linkend="sec.nfs.info" xrefstyle="SectTitleOnPage"/>.
   </para>
   <para>
    Click <guimenu>Next</guimenu>. The dialog that follows has two sections.
    The upper half consists of two columns named
    <guimenu>Directories</guimenu> and <guimenu>Bind Mount Targets</guimenu>
    <remark>in the UI, it is spelled "Bindmount",
    ke</remark>
    . <guimenu>Directories</guimenu> is a directly editable column that
    lists the directories to export.
   </para>
   <para>
    For a fixed set of clients, there are two types of directories that can
    be exported&mdash;directories that act as pseudo root file systems and
    those that are bound to some subdirectory of the pseudo file system.
    This pseudo file system acts as a base point under which all file
    systems exported for the same client set take their place. For a client
    or set of clients, only one directory on the server can be configured as
    pseudo root for export. For this client, export multiple directories by
    binding them to some existing subdirectory in the pseudo root.
   </para>
   <figure pgwide="0">
    <title>Exporting Directories with NFSv4</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="nfs_001a.png" width="75%" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="nfs_001a.png" width="75%" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>
   <para>
    In the lower half of the dialog, enter the client (wild card) and export
    options for a particular directory. After adding a directory in the
    upper half, another dialog for entering the client and option
    information pops up automatically. After that, to add a new client
    (client set), click <guimenu>Add Host</guimenu>.
   </para>
   <para>
    In the small dialog that opens, enter the host wild card. There are four
    possible types of host wild cards that can be set for each host: a
    single host (name or IP address), netgroups, wild cards (such as
    <literal>*</literal> indicating all machines can access the server), and
    IP networks. Then, in <guimenu>Options</guimenu>, include
    <literal>fsid=0</literal> in the comma-separated list of options to
    configure the directory as pseudo root. If this directory needs to be
    bound to another directory under an already configured pseudo root, make
    sure that a target bind path is given in the option list with
    <literal>bind=/target/path</literal>.
   </para>
   <para>
    For example, suppose that the directory <filename>/exports</filename> is
    chosen as the pseudo root directory for all the clients that can access
    the server. Then add this in the upper half and make sure that the
    options entered for this directory include <literal>fsid=0</literal>. If
    there is another directory, <filename>/data</filename>, that also needs
    to be NFSv4 exported, add this directory to the upper half. While
    entering options for this, make sure that
    <literal>bind=/exports/data</literal> is in the list and that
    <filename>/exports/data</filename> is an already existing subdirectory
    of <filename>/exports</filename>. Any change in the option
    <systemitem>bind=/target/path</systemitem>, whether addition, deletion,
    or change in value, is reflected in <guimenu>Bindmount
    Targets</guimenu>. This column is not a directly editable column, but
    instead summarizes directories and their nature. After all information
    is provided, click <guimenu>Finish</guimenu> to complete the
    configuration. The service will become available immediately.
   </para>
  </sect2>

  <sect2 id="sec.nfs.exportv23">
   <title>NFSv3 and NFSv2 Exports</title>
   <para>
    Make sure that <guimenu>Enable NFSv4</guimenu> is not checked in the
    initial dialog before clicking <guimenu>Next</guimenu>.
   </para>
   <para>
    The next dialog has two parts. In the upper text field, enter the
    directories to export. Below, enter the hosts that should have access to
    them. There are four types of host wild cards that can be set for each
    host: a single host (name or IP address), netgroups, wild cards (such as
    <literal>*</literal> indicating all machines can access the server), and
    IP networks.
    <remark>rwalter: more examples might be useful in the future</remark>
   </para>
   <para>
    This dialog is shown in
    <xref linkend="fig.nfs.export23" xrefstyle="FigureOnPage"/>. Find a more
    thorough explanation of these options in <command>man exports</command>.
    Click <guimenu>Finish</guimenu> to complete the configuration.
   </para>
   <figure pgwide="0" id="fig.nfs.export23">
    <title>Exporting Directories with NFSv2 and v3</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="nfs_002a.png" width="75%" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="nfs_002a.png" width="75%" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 id="sec.nfs.export.coexisting">
   <title>Coexisting v3 and v4 Exports</title>
   <para>
    Both, NFSv3 and NFSv4 exports can coexist on a server. After enabling
    the support for NFSv4 in the initial configuration dialog, those exports
    for which <systemitem>fsid=0</systemitem> and
    <systemitem>bind=/target/path</systemitem> are not included in the
    option list are considered v3 exports. Consider the example in
    <xref linkend="fig.inst.nfsserver2" xrefstyle="FigureOnPage"/>. If you
    add another directory, such as <filename>/data2</filename>, using
    <guimenu>Add Directory</guimenu> then in the corresponding options list
    do not mention either <systemitem>fsid=0</systemitem> or
    <systemitem>bind=/target/path</systemitem>, this export acts as a v3
    export.
   </para>
   <important>
    <para>
     Automatic Firewall Configuration
    </para>
    <para>
     If SuSEfirewall2 is active on your system, &yast; adapts its
     configuration for the NFS server by enabling the <literal>nfs</literal>
     service when <guimenu>Open Ports in Firewall</guimenu> is selected.
    </para>
   </important>
  </sect2>
 </sect1>
 <sect1 id="sec.nfs.export.manual" os="osuse;sles">
  <title>Exporting File Systems Manually</title><indexterm>

  <primary>NFS</primary>

  <secondary>exporting</secondary></indexterm>

  <para>
   The configuration files for the NFS export service are
   <filename>/etc/exports</filename> and
   <filename>/etc/sysconfig/nfs</filename>. In addition to these files,
   <filename>/etc/idmapd.conf</filename> is needed for the NFSv4 server
   configuration. To start or restart the services, run the command
   <command>rcnfsserver restart</command>. This also starts the
   <literal>rpc.idmapd</literal> if NFSv4 is configured in
   <filename>/etc/sysconfig/nfs</filename>. The NFS server depends on a
   running RPC portmapper. Therefore, also start or restart the portmapper
   service with <command>rcrpcbind restart</command>.
  </para>

  <sect2 id="sec.nfs.manexportv4">
   <title>Exporting File Systems with NFSv4</title>
   <para>
    NFSv4 is the latest version of NFS protocol available on &productname;.
    Configuring directories for export with NFSv4 differs slightly from
    previous NFS versions.
   </para>
   <sect3 id="sec.nfs.exports">
<!-- really need this subsection? -->
<!-- don't know, this is more like a listing in a bigger scope
     Better using sect3 than variablelist. 2010-07-07, ke -->
    <title>/etc/exports</title>
    <para>
     The <filename>/etc/exports</filename> file contains a list of entries.
     Each entry indicates a directory that is shared and how it is shared. A
     typical entry in <filename>/etc/exports</filename> consists of:
    </para>
<screen>/shared/directory   host(option_list)</screen>
    <para>
     For example:
    </para>
<screen>/export   192.168.1.2(rw,fsid=0,sync,crossmnt)
/export/data   192.168.1.2(rw,bind=/data,sync)
</screen>
    <para>
     Here the IP address <literal>192.168.1.2</literal> is used to identify
     the allowed client. You can also use the name of the host, a wild card
     indicating a set of hosts (<literal>*.abc.com</literal>,
     <literal>*</literal>, etc.), or netgroups
     (<literal>@my-hosts</literal>).
    </para>
    <para>
     The directory which specifies <literal>fsid=0</literal> is special in
     that it is the root of the filesystem that is exported, sometime
     referred to as the pseudo root filesystem. This directory must also
     have the <literal>crossmnt</literal> for correct operation with NFSv4.
     All other directories exported via NFSv4 must be mounted below this
     point. If you want to export a directory that is not within the
     exported root, it needs to be bound into the exported tree. This can be
     done using the <literal>bind=</literal> syntax.
    </para>
    <para>
     In the example above, <filename>/data</filename> is not within
     <filename>/export</filename>, so we export
     <filename>/export/data</filename>, and specify that the
     <filename>/data</filename> directory should be bound to that name. The
     directory <filename>/export/data</filename> must exist and should
     normally be empty.
    </para>
    <para>
     When clients mount from this server, they just mount
     <literal>servername:/</literal> rather than
     <literal>servername:/export</literal>. It is not necessary to mount
     <literal>servername:/data</literal>, because it will automatically
     appear beneath wherever <literal>servername:/</literal> was mounted.
    </para>
   </sect3>
   <sect3 id="sec.nfs.sysconfig">
    <title>/etc/sysconfig/nfs</title>
    <para>
     The <filename>/etc/sysconfig/nfs</filename> file contains a few
     parameters that determine NFSv4 server daemon behavior. Importantly,
     the parameter <systemitem>NFS4_SUPPORT</systemitem> must be set to
     <literal>yes</literal>. <systemitem>NFS4_SUPPORT</systemitem>
     determines whether the NFS server supports NFSv4 exports and clients.
    </para>
   </sect3>
   <sect3 id="sec.nfs.idmapd">
    <title>/etc/idmapd.conf</title>
    <para>
     Every user on a Linux machine has a name and ID. idmapd does the
     name-to-ID mapping for NFSv4 requests to the server and replies to the
     client. It must be running on both server and client for NFSv4, because
     NFSv4 uses only names for its communication.
    </para>
    <para>
     Make sure that there is a uniform way in which usernames and IDs (uid)
     are assigned to users across machines that might probably be sharing
     file systems using NFS. This can be achieved by using NIS, LDAP, or any
     uniform domain authentication mechanism in your domain.
    </para>
    <para>
     The parameter <literal>Domain</literal> must be set the same for both,
     client and server in the <filename>/etc/idmapd.conf</filename> file. If
     you are not sure, leave the domain as <literal>localdomain</literal> in
     the server and client files. A sample configuration file looks like the
     following:
    </para>
<screen>[General] 

Verbosity = 0 
Pipefs-Directory = /var/lib/nfs/rpc_pipefs
Domain = localdomain

[Mapping]

Nobody-User = nobody
Nobody-Group = nobody
</screen>
    <para>
     For further reference, read the man page of <literal>idmapd</literal>
     and <literal>idmapd.conf</literal>; <literal>man idmapd</literal>,
     <literal>man idmapd.conf</literal>.
    </para>
   </sect3>
   <sect3 id="sec.nfs.services">
    <title>Starting and Stopping Services</title>
    <para>
     After changing <filename>/etc/exports</filename> or
     <filename>/etc/sysconfig/nfs</filename>, start or restart the NFS
     server service with <command>rcnfsserver restart</command>. After
     changing <filename>/etc/idmapd.conf</filename>, reload the
     configuration file with the command <command>killall -HUP
     rpc.idmapd</command>.
    </para>
    <para>
     If the NFS service needs to start at boot time, run the command
     <command>chkconfig nfsserver on</command>.
    </para>
   </sect3>
  </sect2>

  <sect2 id="sec.nfs.manualexportv23">
   <title>Exporting File Systems with NFSv2 and NFSv3</title>
   <para>
    This section is specific to NFSv3 and NFSv2 exports. Refer to
    <xref linkend="sec.nfs.exportv4" xrefstyle="HeadingOnPage"/> for
    exporting with NFSv4.
   </para>
   <para>
    Exporting file systems with NFS involves two configuration files:
    <filename>/etc/exports</filename> and
    <filename>/etc/sysconfig/nfs</filename>. A typical
    <filename>/etc/exports</filename> file entry is in the format:
   </para>
<screen>/shared/directory   host(list_of_options)</screen>
   <para>
    For example:
   </para>
<screen>/export   192.168.1.2(rw,sync)</screen>
   <para>
    Here, the directory <filename>/export</filename> is shared with the host
    <literal>192.168.1.2</literal> with the option list
    <systemitem>rw,sync</systemitem>. This IP address can be replaced with a
    client name or set of clients using a wild card (such as
    <literal>*.abc.com</literal>) or even netgroups.
   </para>
   <para>
    For a detailed explanation of all options and their meaning, refer to
    the man page of <command>exports</command> (<command>man
    exports</command>).
   </para>
   <para>
    After changing <filename>/etc/exports</filename> or
    <filename>/etc/sysconfig/nfs</filename>, start or restart the NFS server
    using the command <command>rcnfsserver restart</command>.
   </para>
  </sect2>
 </sect1>
 <sect1 id="sec.nfs.kerberos">
  <title>NFS with Kerberos</title>

  <para>
   To use Kerberos authentication for NFS, GSS security must be enabled. To
   do so, select <guimenu>Enable GSS Security</guimenu> in the initial
   &yast; NFS Server dialog. You must have a working Kerberos server to use
   this feature. &yast; does not set up the server but just uses the
   provided functionality. If you want to use Kerberos authentication in
   addition to the &yast; configuration, complete at least the following
   steps before running the NFS configuration:
  </para>

  <procedure>
   <step>
    <para>
     Make sure that both the server and the client are in the same Kerberos
     domain. They must access the same KDC (Key Distribution Center) server
     and share their <filename>krb5.keytab</filename> file (the default
     location on any machine is <filename>/etc/krb5.keytab</filename>). For
     more information about Kerberos, see
     <xref linkend="cha.security.kerberos" />.
    </para>
   </step>
   <step>
    <para>
     Start the gssd service on the client with <command>rcgssd
     start</command>.
    </para>
   </step>
   <step os="osuse;sles">
    <para>
     Start the svcgssd service on the server with <command>rcsvcgssd
     start</command>.
    </para>
   </step>
  </procedure>

  <para>
   For more information about configuring kerberized NFS, refer to the links
   in <xref linkend="sec.nfs.info" xrefstyle="SectTitleOnPage"/>.
  </para>
 </sect1>
 <sect1 id="sec.nfs.info">
  <title>For More Information</title>

  <para>
   As well as the man pages of <command>exports</command>,
   <command>nfs</command>, and <command>mount</command>, information about
   configuring an NFS server and client is available in
   <filename>/usr/share/doc/packages/nfsidmap/README</filename>. Online
   documentation can be found at the following Web documents:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Find the detailed technical documentation online at
     <ulink url="http://nfs.sourceforge.net/">SourceForge</ulink>.
    </para>
   </listitem>
   <listitem>
    <para>
     For instructions for setting up kerberized NFS, refer to
     <ulink url="http://www.citi.umich.edu/projects/nfsv4/linux/krb5-setup.html">NFS
     Version 4 Open Source Reference Implementation</ulink>.
    </para>
   </listitem>
   <listitem>
    <para>
     If you have questions on NFSv4, refer to the
     <ulink url="http://www.citi.umich.edu/projects/nfsv4/linux/faq/">Linux
     NFSv4 FAQ</ulink>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>
