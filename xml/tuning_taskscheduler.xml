<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<chapter id="cha.tuning.taskscheduler">
 <title>Tuning the Task Scheduler</title>
 <para>
  Modern operating systems, such as &productnamereg;, normally run many
  different tasks at the same time. For example, you can be searching in a
  text file while receiving an e-mail and copying a big file to an external
  hard drive. These simple tasks require many additional processes to be run
  by the system. To provide each task with its required system resources,
  the Linux kernel needs a tool to distribute available system resources to
  individual tasks. And this is exactly what <emphasis>task
  scheduler</emphasis> does.
 </para>
 <para>
  The following sections explain the most important terms related to process
  scheduling. They also introduce information about the task scheduler
  policy, scheduling algorithm, description of the task scheduler used by
  &productname;, and references to other sources of relevant information.
 </para>
 <sect1 id="sec.tuning.taskscheduler.intro">
  <title>Introduction</title>

  <para>
   The Linux kernel controls the way tasks (or processes) are managed in the
   running system. The task scheduler, sometimes called <emphasis>process
   scheduler</emphasis>, is the part of the kernel that decides which task
   to run next. It is one of the core components of a multitasking operating
   system (such as Linux), being responsible for best utilizing system
   resources to guarantee that multiple tasks are being executed
   simultaneously.
  </para>

  <sect2 id="sec.tuning.taskscheduler.intro.preemption">
   <title>Preemption</title>
   <para>
    The theory behind task scheduling is very simple. If there are runnable
    processes in a system, at least one process must always be running. If
    there are more runnable processes than processors in a system, not all
    the processes can be running all the time.
   </para>
   <para>
    Therefore, some processes need to be stopped temporarily, or
    <emphasis>suspended</emphasis>, so that others can be running again. The
    scheduler decides what process in the queue will run next.
   </para>
   <para>
    As already mentioned, Linux, like all other Unix variants, is a
    <emphasis>multitasking</emphasis> operating system. That means that
    several tasks can be running at the same time. Linux provides a so
    called <emphasis>preemptive</emphasis> multitasking, where the scheduler
    decides when a process is suspended. This forced suspension is called
    <emphasis>preemption</emphasis>. All Unix flavors have been providing
    preemptive multitasking since the beginning.
   </para>
  </sect2>

  <sect2 id="sec.tuning.taskscheduler.intro.timeslice">
   <title>Timeslice</title>
   <para>
    The time period for which a process will be running before it is
    <emphasis>preempted</emphasis> is defined in advance. It is called a
    process' <emphasis>timeslice</emphasis> and represents the amount of
    processor time that is provided to each process. By assigning
    timeslices, the scheduler makes global decisions for the running system,
    and prevents individual processes from dominating over the processor
    resources.
   </para>
  </sect2>

  <sect2 id="sec.tuning.taskscheduler.intro.priority">
   <title>Process Priority</title>
   <para>
    The scheduler evaluates processes based on their priority. To calculate
    the current priority of a process, the task scheduler uses complex
    algorithms. As a result, each process is given a value according to
    which it is <quote>allowed</quote> to run on a processor.
   </para>
  </sect2>
 </sect1>
 <sect1 id="sec.tuning.taskscheduler.policy.class">
  <title>Process Classification</title>

  <para>
   Processes are usually classified according to their purpose and behavior.
   Although the borderline is not always clearly distinct, generally two
   criterias are used to sort them. These criteria are independent and do
   not exclude each other.
  </para>

  <para>
   One approach is to classify a process either
   <emphasis>I/O-bound</emphasis> or <emphasis>processor-bound</emphasis>.
  </para>

  <variablelist>
   <varlistentry>
    <term>I/O-bound</term>
    <listitem>
     <para>
      I/O stands for Input/Output devices, such as keyboards, mice, or
      optical and hard disks. <emphasis>I/O-bound processes</emphasis> spend
      the majority of time submitting and waiting for requests. They are run
      very frequently, but for short time intervals, not to block other
      processes waiting for I/O requests.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>processor-bound</term>
    <listitem>
     <para>
      On the other hand, <emphasis>processor-bound</emphasis> tasks use
      their time to execute a code, and usually run until they are preempted
      by the scheduler. They do not block processes waiting for I/O
      requests, and, therefore, can be run less frequently but for longer
      time intervals.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Another approach is to divide processes by either being
   <emphasis>interactive</emphasis>, <emphasis>batch</emphasis>, or
   <emphasis>real-time</emphasis> ones.
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <emphasis>Interactive</emphasis> processes spend a lot of time waiting
     for I/O requests, such as keyboard or mouse operations. The scheduler
     must wake up such process quickly on user request, or the user will
     find the environment unresponsive. The typical delay is approximately
     100 ms. Office applications, text editors or image manipulation
     programs represent typical interactive processes.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Batch</emphasis> processes often run in the background and do
     not need to be responsive. They usually receive lower priority from the
     scheduler. Multimedia converters, database search engines, or log files
     analyzers are typical examples of batch processes.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Real-time</emphasis> processes must never be blocked by
     low-priority processes, and the scheduler guarantees a short response
     time to them. Applications for editing multimedia content are a good
     example here.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 id="sec.tuning.taskscheduler.o1">
  <title>O(1) Scheduler</title>

  <para>
   The Linux kernel version 2.6 introduced a new task scheduler, called O(1)
   scheduler (see
   <ulink
    url="http://en.wikipedia.org/wiki/Big_O_notation">Big O
   notation</ulink>), It was used as the default scheduler up to Kernel
   version 2.6.22. Its main task is to schedule tasks within a fixed amount
   of time, no matter how many runnable processes there are in the system.
  </para>

  <para>
   The scheduler calculates the timeslices dynamically. However, to
   determine the appropriate timeslice is a complex task: Too long
   timeslices cause the system to be less interactive and responsive, while
   too short ones make the processor waste a lot of time on the overhead of
   switching the processes too frequently. The default timeslice is usually
   rather low, for example 20ms. The scheduler determines the timeslice
   based on priority of a process, which allows the processes with higher
   priority to run more often and for a longer time.
  </para>

  <para>
   A process does not have to utilize all its timeslice at once. For
   instance, a process with a timeslice of 150ms does not have to be running
   for 150ms in one go. It can be running in five different schedule slots
   for 30ms instead. Interactive tasks typically benefit from this approach
   because they do not need such a large timeslice at once while they need
   to be responsive as long as possible.
  </para>

  <para>
   The scheduler also assigns process priorities dynamically. It monitors
   the processes' behavior and, if needed, adjusts its priority. For
   example, a process which is being suspended for a long time is brought up
   by increasing its priority.
  </para>
 </sect1>
 <sect1 id="sec.tuning.taskscheduler.cfs">
  <title>Completely Fair Scheduler</title>

  <para>
   Since the Linux kernel version 2.6.23, a new approach has been taken to
   the scheduling of runnable processes. Completely Fair Scheduler (CFS)
   became the default Linux kernel scheduler. Since then, important changes
   and improvements have been made. The information in this chapter applies
   to &productname; with kernel version 2.6.32. The scheduler environment
   was divided into several parts, and three main new features were
   introduced:
  </para>

  <variablelist>
   <varlistentry>
    <term>Modular Scheduler Core</term>
    <listitem>
     <para>
      The core of the scheduler was enhanced with <emphasis>scheduling
      classes</emphasis>. These classes are modular and represent scheduling
      policies.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Completely Fair Scheduler</term>
    <listitem>
     <para>
      Introduced in kernel 2.6.23 and extended in 2.6.24, CFS tries to
      assure that each process obtains its <quote>fair</quote> share of the
      processor time.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Group Scheduling</term>
    <listitem>
     <para>
      For example, if you split processes into groups according to which
      user is running them, CFS tries to provide each of these groups with
      the same amount of processor time.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   As a result, CFS brings more optimized scheduling for both servers and
   desktops.
  </para>

  <sect2 id="sec.tuning.taskscheduler.cfs.howitworks">
   <title>How CFS Works</title>
   <para>
    CFS tries to guarantee a fair approach to each runnable task. To find
    the most balanced way of task scheduling, it uses the concept of
    <emphasis>red-black tree</emphasis>. A red-black tree is a type of
    self-balancing data search tree which provides inserting and removing
    entries in a reasonable way so that it remains well balanced. For more
    information, see the wiki pages of
    <ulink
    url="http://en.wikipedia.org/wiki/Red_black_tree">Red-black
    tree</ulink>.
   </para>
   <para>
    When a task enters into the <emphasis>run queue</emphasis> (a planned
    time line of processes to be executed next), the scheduler records the
    current time. While the process waits for processor time, its
    <quote>wait</quote> value gets incremented by an amount derived from the
    total number of tasks currently in the run queue and the process
    priority. As soon as the processor runs the task, its
    <quote>wait</quote> value gets decremented. If the value drops below a
    certain level, the task is preempted by the scheduler and other tasks
    get closer to the processor. By this algorithm, CFS tries to reach the
    ideal state where the <quote>wait</quote> value is always zero.
   </para>
  </sect2>

  <sect2 id="sec.tuning.taskscheduler.cfs.grouping">
   <title>Grouping Processes</title>
   <para>
    Since the Linux kernel version 2.6.24, CFS can be tuned to be fair to
    users or groups rather than to tasks only. Runnable tasks are then
    grouped to form entities, and CFS tries to be fair to these entities
    instead of individual runnable tasks. The scheduler also tries to be
    fair to individual tasks within these entities.
   </para>
   <para>
    Tasks can be grouped in two mutually exclusive ways:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      By user IDs
     </para>
    </listitem>
    <listitem>
     <para>
      By kernel control groups.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    The way the kernel scheduler lets you group the runnable tasks depends
    on setting the kernel compile-time options
    <literal>CONFIG_FAIR_USER_SCHED</literal> and
    <literal>CONFIG_FAIR_CGROUP_SCHED</literal>. The default setting in
    &productnamereg; &productnumber; is to use control groups, which lets
    you create groups as needed. For more information, see
    <xref linkend="cha.tuning.cgroups"/>.
   </para>
  </sect2>

  <sect2 id="sec.tuning.taskscheduler.cfs.kernelconfig">
   <title>Kernel Configuration Options</title>
   <para>
    Basic aspects of the task scheduler behavior can be set through the
    kernel configuration options. Setting these options is part of the
    kernel compilation process. Because kernel compilation process is a
    complex task and out of this document's scope, refer to relevant source
    of information (for example
    <ulink
     url="http://en.opensuse.org/Configure,_Build_and_Install_a_Custom_Linux_Kernel"/>).
   </para>
   <warning>
    <title>Kernel Compilation</title>
    <para>
     If you run &productname; on a kernel that was not shipped with it, for
     example on a self-compiled kernel, you loose the entire support
     entitlement.
    </para>
   </warning>
  </sect2>

  <sect2 id="sec.tuning.taskscheduler.cfs.terms">
   <title>Terminology</title>
   <para>
    Documents regarding task scheduling policy often use several technical
    terms which you need to know to understand the information correctly.
    Here are some of them:
   </para>
   <variablelist>
    <varlistentry>
     <term>Latency</term>
     <listitem>
      <para>
       Delay between the time a process is scheduled to run and the actual
       process execution.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Granularity</term>
     <listitem>
      <para>
       The relation between granularity and latency can be expressed by the
       following equation:
      </para>
<screen>gran = ( lat / rtasks ) - ( lat / rtasks / rtasks )</screen>
      <para>
       where <emphasis>gran</emphasis> stands for granularity,
       <emphasis>lat</emphasis> stand for latency, and
       <emphasis>rtasks</emphasis> is the number of running tasks.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>SCHED_BATCH</term>
     <listitem>
      <para>
       Scheduling policy designed for CPU-intensive tasks.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>SCHED_OTHER</term>
     <listitem>
      <para>
       Default Linux time-sharing scheduling policy.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 id="sec.tuning.taskscheduler.cfs.tuning">
   <title>Runtime Tuning</title>
   <para>
    The <command>sysctl</command> interface for examining and changing
    kernel parameters at runtime introduces important variables by means of
    which you can change the default behavior of the task scheduler. The
    syntax of the <command>sysctl</command> is simple, and all the following
    commands must be entered on the command line as &rootuser;.
   </para>
   <para>
    To read a value from a kernel variable, enter
   </para>
<screen><command>sysctl <replaceable>variable</replaceable></command></screen>
   <para>
    To assign a value, enter
   </para>
<screen><command>sysctl <replaceable>variable</replaceable>=<replaceable>value</replaceable></command></screen>
   <para>
    To get a list of all scheduler related <command>sysctl</command>
    variables, enter
   </para>
<screen><command>sysctl <option>-A</option></command> | <command>grep <replaceable>"sched"</replaceable></command> | <command>grep <option>-v</option> <replaceable>"domain"</replaceable></command></screen>
<screen>&wsIIIname;:~ # sysctl -A | grep "sched" | grep -v "domain"
kernel.sched_child_runs_first = 0
kernel.sched_min_granularity_ns = 1000000
kernel.sched_latency_ns = 5000000
kernel.sched_wakeup_granularity_ns = 1000000
kernel.sched_shares_ratelimit = 250000
kernel.sched_tunable_scaling = 1
kernel.sched_shares_thresh = 4
kernel.sched_features = 15834238
kernel.sched_migration_cost = 500000
kernel.sched_nr_migrate = 32
kernel.sched_time_avg = 1000
kernel.sched_rt_period_us = 1000000
kernel.sched_rt_runtime_us = 950000
kernel.sched_compat_yield = 0</screen>
   <para>
    Note that variables ending with <quote>_ns</quote> and
    <quote>_us</quote> accept values in nanoseconds and microseconds,
    respectively.
   </para>
<!-- fs 2010-07-01: Commenting, since we give some more tuning advice below
   <para>
    According to Ingo Molnar, the author of CFS, there is only one important
    tuning option for CFS:
    <literal>kernel.sched_min_granularity_ns</literal>. It can be used to
    fine-tune the scheduler from low-latency response suitable for desktops,
    to server deployment giving more priority to batch tasks.
   </para>
-->
   <para>
    A list of the most important task scheduler <command>sysctl</command>
    tuning variables (located at <filename>/proc/sys/kernel/</filename>)
    with a short description follows:
   </para>
   <variablelist>
    <varlistentry>
     <term><systemitem>sched_child_runs_first</systemitem>
     </term>
     <listitem>
      <para>
       A freshly forked child runs before the parent continues execution.
       Setting this parameter to <literal>1</literal> is beneficial for an
       application in which the child performs an execution after fork. For
       example <command>make
       <option>-j<replaceable>&lt;NO_CPUS&gt;</replaceable></option></command>
       performs better when sched_child_runs_first is turned off. The
       default value is <literal>0</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_compat_yield</systemitem>
     </term>
     <listitem>
      <para>
       Enables the aggressive yield behavior of the old 0(1) scheduler. Java
       applications that use synchronization extensively perform better with
       this value set to <literal>1</literal>. Only use it when you see a
       drop in performance. The default value is <literal>0</literal>.
      </para>
      <para>
       Expect applications that depend on the sched_yield() syscall behavior
       to perform better with the value set to <literal>1</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_migration_cost</systemitem>
     </term>
     <listitem>
      <para>
       Amount of time after the last execution that a task is considered to
       be <quote>cache hot</quote> in migration decisions. A
       <quote>hot</quote> task is less likely to be migrated, so increasing
       this variable reduces task migrations. The default value is
       <literal>500000</literal> (ns).
      </para>
      <para>
       If the CPU idle time is higher than expected when there are runnable
       processes, try reducing this value. If tasks bounce between CPUs or
       nodes too often, try increasing it.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_latency_ns</systemitem>
     </term>
     <listitem>
      <para>
       Targeted preemption latency for CPU bound tasks. Increasing this
       variable increases a CPU bound task's timeslice. A task's timeslice
       is its weighted fair share of the scheduling period:
      </para>
      <para>
       timeslice = scheduling period * (task's weight/total weight of tasks
       in the run queue)
      </para>
      <para>
       The task's weight depends on the task's nice level and the scheduling
       policy. Minimum task weight for a SCHED_OTHER task is 15,
       corresponding to nice 19. The maximum task weight is 88761,
       corresponding to nice -20.
      </para>
      <para>
       Timeslices become smaller as the load increases. When the number of
       runnable tasks exceeds
       <systemitem>sched_latency_ns</systemitem>/<systemitem>sched_min_granularity_ns</systemitem>,
       the slice becomes number_of_running_tasks *
       <systemitem>sched_min_granularity_ns</systemitem>. Prior to that, the
       slice is equal to <systemitem>sched_latency_ns</systemitem>.
      </para>
      <para>
       This value also specifies the maximum amount of time during which a
       sleeping task is considered to be running for entitlement
       calculations. Increasing this variable increases the amount of time a
       waking task may consume before being preempted, thus increasing
       scheduler latency for CPU bound tasks. The default value is
       <literal>20000000</literal> (ns).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_min_granularity_ns</systemitem>
     </term>
     <listitem>
      <para>
       Minimal preemption granularity for CPU bound tasks. See
       <systemitem>sched_latency_ns</systemitem> for details. The default
       value is <literal>4000000</literal> (ns).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_wakeup_granularity_ns</systemitem>
     </term>
     <listitem>
      <para>
       The wake-up preemption granularity. Increasing this variable reduces
       wake-up preemption, reducing disturbance of compute bound tasks.
       Lowering it improves wake-up latency and throughput for latency
       critical tasks, particularly when a short duty cycle load component
       must compete with CPU bound components. The default value is
       <literal>5000000</literal> (ns).
      </para>
      <warning>
       <para>
        Settings larger than half of
        <systemitem>sched_latency_ns</systemitem> will result in zero
        wake-up preemption and short duty cycle tasks will be unable to
        compete with CPU hogs effectively.
       </para>
      </warning>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_rt_period_us</systemitem>
     </term>
     <listitem>
      <para>
       Period over which real-time task bandwidth enforcement is measured.
       The default value is <literal>1000000</literal> (µs).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_rt_runtime_us</systemitem>
     </term>
     <listitem>
      <para>
       Quantum allocated to real-time tasks during sched_rt_period_us.
       Setting to -1 disables RT bandwidth enforcement. By default, RT tasks
       may consume 95%CPU/sec, thus leaving 5%CPU/sec or 0.05s to be used by
       SCHED_OTHER tasks.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_features</systemitem>
     </term>
     <listitem>
      <para>
       Provides information about specific debugging features.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_stat_granularity_ns</systemitem>
     </term>
     <listitem>
      <para>
       Specifies the granularity for collecting task scheduler statistics.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_nr_migrate</systemitem>
     </term>
     <listitem>
      <para>
       Controls how many tasks can be moved across processors through
       migration software interrupts (softirq). If a large number of tasks
       is created by SCHED_OTHER policy, they will all be run on the same
       processor. The default value is <literal>32</literal>. Increasing
       this value gives a performance boost to large SCHED_OTHER threads at
       the expense of increased latencies for real-time tasks.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

<!-- fs commenting, since the package schedtool is not available for
     any SUSE Linux/opensuse distribution
     but see FATE#310074 !!

  <sect2 id="sec.tuning.taskscheduler.cfs.tuning_other">
   <title>Other Tuning Options</title>
   <para>
    Long running, non-interactive tasks (that don't like preemption) and batch
    workloads may benefit from setting the scheduler policy to SCHED_BATCH.
    Changing the scheduling policy of the shell to SCHED_BATCH can be done by:
   </para>
<screen>~# schedtool -B $$
~# <replaceable>start_your_program</replaceable>
</screen>
   <para>
    After doing this, all programs being started in this shell will inherit
    using the SCHED_BATCH scheduling policy instead of SCHED_NORMAL.
   </para>
   <note>
    <para>
     You need to have the package <systemitem
      class="ressource">schedtool</systemitem> installed. 
    </para>
   </note>
  </sect2>
-->

  <sect2 id="sec.tuning.taskscheduler.cfs.debug">
   <title>Debugging Interface and Scheduler Statistics</title>
   <para>
    CFS comes with a new improved debugging interface, and provides runtime
    statistics information. Relevant files were added to the
    <filename>/proc</filename> file system, which can be examined simply
    with the <command>cat</command> or <command>less</command> command. A
    list of the related <filename>/proc</filename> files follows with their
    short description:
   </para>
   <variablelist>
    <varlistentry>
     <term><filename>/proc/sched_debug</filename>
     </term>
     <listitem>
      <para>
       Contains the current values of all tunable variables (see
       <xref linkend="sec.tuning.taskscheduler.cfs.tuning"/>) that affect
       the task scheduler behavior, CFS statistics, and information about
       the run queue on all available processors.
      </para>
<screen>&wsIIIname;:~ # less /proc/sched_debug
Sched Debug Version: v0.09, 2.6.32.8-0.3-default #1
now at 2413026096.408222 msecs
  .jiffies                                 : 4898148820
  .sysctl_sched_latency                    : 5.000000
  .sysctl_sched_min_granularity            : 1.000000
  .sysctl_sched_wakeup_granularity         : 1.000000
  .sysctl_sched_child_runs_first           : 0.000000
  .sysctl_sched_features                   : 15834238
  .sysctl_sched_tunable_scaling            : 1 (logaritmic)

cpu#0, 1864.411 MHz
  .nr_running                    : 1
  .load                          : 1024
  .nr_switches                   : 37539000
  .nr_load_updates               : 22950725
[...]
cfs_rq[0]:/
  .exec_clock                    : 52940326.803842
  .MIN_vruntime                  : 0.000001
  .min_vruntime                  : 54410632.307072
  .max_vruntime                  : 0.000001
[...]
rt_rq[0]:/
  .rt_nr_running                 : 0
  .rt_throttled                  : 0
  .rt_time                       : 0.000000
  .rt_runtime                    : 950.000000

runnable tasks:
  task  PID   tree-key    switches prio exec-runtime    sum-exec sum-sleep
--------------------------------------------------------------------------
R cat 16884 54410632.307072    0   120  54410632.307072 13.836804 0.000000</screen>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/proc/schedstat</filename>
     </term>
     <listitem>
      <para>
       Displays statistics relevant to the current run queue. Also
       domain-specific statistics for SMP systems are displayed for all
       connected processors. Because the output format is not user-friendly,
       read the contents of
       <filename>/usr/src/linux/Documentation/scheduler/sched-stats.txt</filename>
       for more information.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/proc/<replaceable>PID</replaceable>/sched</filename>
     </term>
     <listitem>
      <para>
       Displays scheduling information on the process with id
       <replaceable>PID</replaceable>.
      </para>
<screen>&wsIIIname;:~ # cat /proc/`pidof nautilus`/sched
 nautilus (4009, #threads: 1)
 ---------------------------------------------------------
 se.exec_start                      :    2419575150.560531
 se.vruntime                        :      54549795.870151
 se.sum_exec_runtime                :       4867855.829415
 se.avg_overlap                     :             0.401317
 se.avg_wakeup                      :             3.247651
 se.avg_running                     :             0.323432
 se.wait_start                      :             0.000000
 se.sleep_start                     :    2419575150.560531
 [...]
 nr_voluntary_switches              :               938552
 nr_involuntary_switches            :                71872
 se.load.weight                     :                 1024
 policy                             :                    0
 prio                               :                  120
 clock-delta                        :                  109</screen>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 id="cha.tuning.taskscheduler.moreinfo">
  <title>For More Information</title>

  <para>
   To get a compact knowledge about Linux kernel task scheduling, you need
   to explore several information sources. Here are some of them:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     For task scheduler System Calls description, see the relevant manual
     page (for example <command>man 2 sched_setaffinity</command>).
    </para>
   </listitem>
   <listitem>
    <para>
     General information on scheduling is described in
     <ulink
   url="http://en.wikipedia.org/wiki/Scheduling_(computing)">Scheduling</ulink>
     wiki page.
    </para>
   </listitem>
   <listitem>
    <para>
     General information on Linux task scheduling is described in
     <ulink
   url="http://www.ibm.com/developerworks/linux/library/l-scheduler/">Inside
     the Linux scheduler</ulink>.
    </para>
   </listitem>
   <listitem>
    <para>
     Information specific to Completely Fair Scheduler is available in
     <ulink
   url="http://www.ibm.com/developerworks/linux/library/l-cfs/?ca=dgr-lnxw06CFC4Linux">Multiprocessing
     with the Completely Fair Scheduler</ulink>
    </para>
   </listitem>
   <listitem>
    <para>
     Information specific to tuning Completely Fair Scheduler is available
     in
     <ulink
   url="http://www.hotaboutlinux.com/2010/01/tuning-the-linux-kernels-completely-fair-scheduler/">Tuning
     the Linux Kernel’s Completely Fair Scheduler</ulink>
    </para>
   </listitem>
   <listitem>
    <para>
     A useful lecture on Linux scheduler policy and algorithm is available
     in
     <ulink
   url="http://www.inf.fu-berlin.de/lehre/SS01/OS/Lectures/Lecture08.pdf" />.
    </para>
   </listitem>
   <listitem>
    <para>
     A good overview of Linux process scheduling is given in
     <citetitle>Linux Kernel Development</citetitle> by Robert Love
     (ISBN-10: 0-672-32512-8). See
     <ulink
   url="http://www.informit.com/articles/article.aspx?p=101760"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     A very comprehensive overview of the Linux kernel internals is given in
     <citetitle>Understanding the Linux Kernel</citetitle> by Daniel P.
     Bovet and Marco Cesati (ISBN 978-0-596-00565-8).
    </para>
   </listitem>
   <listitem>
    <para>
     Technical information about task scheduler is covered in files under
     <filename>/usr/src/linux/Documentation/scheduler</filename>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>
